{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "from stldecompose import decompose, forecast\n",
    "from stldecompose.forecast_funcs import (naive, drift, mean, seasonal_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prophet(series, timeframe):\n",
    "    \"\"\"\n",
    "    Runs the Prophet \n",
    "    \n",
    "    Key arguments:\n",
    "    --------------\n",
    "    series -- (DataFrame) time series data\n",
    "    timeframe -- (DataFrame) a DataFrame with one column \n",
    "                 consisting of predicted dates\n",
    "\n",
    "    Returns: \n",
    "    --------------\n",
    "    Returns the forecast of the predictions \n",
    "\n",
    "    \"\"\"\n",
    "    model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=False, \n",
    "                    # changepoint_prior_scale=0.001,\n",
    "                    # mcmc_samples=300,\n",
    "                    interval_width=0.95)\n",
    "    model.fit(series)\n",
    "    forecast = model.predict(timeframe)\n",
    "    return forecast, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"../data/exception_hours.csv\", parse_dates=[\"SHIFT_DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "data_clean = data[(data[\"SITE\"]==\"St Paul's Hospital\") |\n",
    "                    (data[\"SITE\"]==\"Mt St Joseph\") |\n",
    "                    (data[\"SITE\"]==\"Holy Family\") |\n",
    "                    (data[\"SITE\"]==\"SVH Langara\") |\n",
    "                    (data[\"SITE\"]==\"Brock Fahrni\") |\n",
    "                    (data[\"SITE\"]==\"Youville Residence\")]\n",
    "data_clean = data_clean[(data_clean[\"JOB_FAMILY\"]==\"DC1000\") |\n",
    "                    (data_clean[\"JOB_FAMILY\"]==\"DC2A00\") |\n",
    "                    (data_clean[\"JOB_FAMILY\"]==\"DC2B00\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataframes\n",
    "data_group = data_clean.groupby([\"JOB_FAMILY\", \"SITE\", \"SUB_PROGRAM\", \"SHIFT_DATE\"]).size().reset_index()\n",
    "data_group = data_group.rename({\"SHIFT_DATE\":\"ds\", 0:\"y\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timeframe data for prediction\n",
    "timeframe_past = pd.DataFrame(pd.date_range(start='2013-01-01', end='2018-12-31', freq=\"D\")).rename({0:\"ds\"}, axis=1)\n",
    "timeframe_future = pd.DataFrame(pd.date_range(start='2019-01-01', end='2019-12-31', freq=\"D\")).rename({0:\"ds\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "start = pd.to_datetime(\"2019-12-31\")-datetime.timedelta(days=4*365)\n",
    "end = pd.to_datetime(\"2019-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = data_clean[\"SITE\"].unique()\n",
    "job_families = data_clean[\"JOB_FAMILY\"].unique()\n",
    "sub_programs = data_clean[\"SUB_PROGRAM\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting - St Paul's Hospital DC2B00 RENAL 6AB : Done\n",
      "Fitting - St Paul's Hospital DC2B00 OR PAR SPH : Done\n",
      "Fitting - St Paul's Hospital DC2B00 HEMODIALYSIS 6CD IC : Done\n",
      "Fitting - St Paul's Hospital DC2B00 PASU 9A 2N 8C : Done\n",
      "Fitting - St Paul's Hospital DC2B00 EMERG SPH : Done\n",
      "Fitting - St Paul's Hospital DC2B00 ICU : Done\n",
      "Fitting - St Paul's Hospital DC2B00 NICU MATERNITY : Done\n",
      "Fitting - St Paul's Hospital DC2B00 MELANIE MULDER : Done\n",
      "Fitting - St Paul's Hospital DC2B00 MED NURSE RELIEF : Done\n",
      "Fitting - St Paul's Hospital DC2B00 IMAGING : Done\n",
      "Fitting - St Paul's Hospital DC2B00 RENAL CDU IAMHD : Done\n",
      "Fitting - St Paul's Hospital DC2B00 10C, CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC2B00 AMBULATORY : Done\n",
      "Fitting - St Paul's Hospital DC2B00 BARBARA HALL : Done\n",
      "Fitting - St Paul's Hospital DC2B00 NURSING UNIT SPH : Done\n",
      "Fitting - St Paul's Hospital DC2B00 PALLIATIVE SRVCS : Done\n",
      "Fitting - St Paul's Hospital DC2B00 DIONNE NORDBY : Done\n",
      "Fitting - St Paul's Hospital DC2B00 CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC2B00 NURSING PRACTICE  EDU : Done\n",
      "Fitting - St Paul's Hospital DC2B00 BLOOD DISORDERS : Done\n",
      "Fitting - St Paul's Hospital DC2B00 SPH INPATIENT : Done\n",
      "Fitting - St Paul's Hospital DC2B00 SPD : Done\n",
      "Fitting - St Paul's Hospital DC2B00 PACIFIC LUNG  CF : Done\n",
      "Fitting - St Paul's Hospital DC2B00 CARDIAC OR, SUPP : Done\n",
      "Fitting - St Paul's Hospital DC2B00 HEN HPN : Done\n",
      "Fitting - St Paul's Hospital DC2B00 NURSING ADMIN : Done\n",
      "Fitting - St Paul's Hospital DC2B00 GER OUTPAT : Done\n",
      "Fitting - St Paul's Hospital DC2B00 STEFANIE MACLEOD : Done\n",
      "Fitting - St Paul's Hospital DC1000 RENAL 6AB : Done\n",
      "Fitting - St Paul's Hospital DC1000 OR PAR SPH : Done\n",
      "Fitting - St Paul's Hospital DC1000 HEMODIALYSIS 6CD IC : Done\n",
      "Fitting - St Paul's Hospital DC1000 PASU 9A 2N 8C : Done\n",
      "Fitting - St Paul's Hospital DC1000 EMERG SPH : Done\n",
      "Fitting - St Paul's Hospital DC1000 ICU : Done\n",
      "Fitting - St Paul's Hospital DC1000 NICU MATERNITY : Done\n",
      "Fitting - St Paul's Hospital DC1000 MELANIE MULDER : Done\n",
      "Fitting - St Paul's Hospital DC1000 MED NURSE RELIEF : Done\n",
      "Fitting - St Paul's Hospital DC1000 IMAGING : Done\n",
      "Fitting - St Paul's Hospital DC1000 RENAL CDU IAMHD : Done\n",
      "Fitting - St Paul's Hospital DC1000 10C, CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC1000 OR BOOKING : Done\n",
      "Fitting - St Paul's Hospital DC1000 SPH CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC1000 AMBULATORY : Done\n",
      "Fitting - St Paul's Hospital DC1000 BARBARA HALL : Done\n",
      "Fitting - St Paul's Hospital DC1000 NURSING UNIT SPH : Done\n",
      "Fitting - St Paul's Hospital DC1000 PALLIATIVE SRVCS : Done\n",
      "Fitting - St Paul's Hospital DC1000 EATING DISORDER : Done\n",
      "Fitting - St Paul's Hospital DC1000 DIONNE NORDBY : Done\n",
      "Fitting - St Paul's Hospital DC1000 CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC1000 LR COMP CLASS : Done\n",
      "Fitting - St Paul's Hospital DC1000 NURSING PRACTICE  EDU : Done\n",
      "Fitting - St Paul's Hospital DC1000 SPH INPATIENT : Done\n",
      "Fitting - St Paul's Hospital DC1000 PACIFIC LUNG  CF : Done\n",
      "Fitting - St Paul's Hospital DC1000 CARDIAC OR, SUPP : Done\n",
      "Fitting - St Paul's Hospital DC1000 WORKPL WS : Done\n",
      "Fitting - St Paul's Hospital DC1000 NURSING ADMIN : Done\n",
      "Fitting - St Paul's Hospital DC1000 FOUNDRY VAN GRANVILLE : Done\n",
      "Fitting - St Paul's Hospital DC1000 STEFANIE MACLEOD : Done\n",
      "Fitting - St Paul's Hospital DC2A00 RENAL 6AB : Done\n",
      "Fitting - St Paul's Hospital DC2A00 OR PAR SPH : Done\n",
      "Fitting - St Paul's Hospital DC2A00 HEMODIALYSIS 6CD IC : Done\n",
      "Fitting - St Paul's Hospital DC2A00 PASU 9A 2N 8C : Done\n",
      "Fitting - St Paul's Hospital DC2A00 EMERG SPH : Done\n",
      "Fitting - St Paul's Hospital DC2A00 ICU : Done\n",
      "Fitting - St Paul's Hospital DC2A00 NICU MATERNITY : Done\n",
      "Fitting - St Paul's Hospital DC2A00 MELANIE MULDER : Done\n",
      "Fitting - St Paul's Hospital DC2A00 MED NURSE RELIEF : Done\n",
      "Fitting - St Paul's Hospital DC2A00 RENAL CDU IAMHD : Done\n",
      "Fitting - St Paul's Hospital DC2A00 10C, CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC2A00 OR BOOKING : Done\n",
      "Fitting - St Paul's Hospital DC2A00 SPH CLINICS : Done\n",
      "Fitting - St Paul's Hospital DC2A00 AMBULATORY : Done\n",
      "Fitting - St Paul's Hospital DC2A00 BARBARA HALL : Done\n",
      "Fitting - St Paul's Hospital DC2A00 NURSING UNIT SPH : Done\n",
      "Fitting - St Paul's Hospital DC2A00 PALLIATIVE SRVCS : Done\n",
      "Fitting - St Paul's Hospital DC2A00 EATING DISORDER : Done\n",
      "Fitting - St Paul's Hospital DC2A00 DIONNE NORDBY : Done\n",
      "Fitting - St Paul's Hospital DC2A00 LR COMP CLASS : Done\n",
      "Fitting - St Paul's Hospital DC2A00 SPH INPATIENT : Done\n",
      "Fitting - St Paul's Hospital DC2A00 SPD : Done\n",
      "Fitting - St Paul's Hospital DC2A00 ACCESS SVCS SPH : Done\n",
      "Fitting - SVH Langara DC2B00 ALDER : Done\n",
      "Fitting - SVH Langara DC1000 ALDER : Done\n",
      "Fitting - SVH Langara DC1000 RES SVCS LAN : Done\n",
      "Fitting - SVH Langara DC2A00 RES SVCS LAN : Done\n",
      "Fitting - Mt St Joseph DC2B00 MSJ OR PAR DT CL : Done\n",
      "Fitting - Mt St Joseph DC2B00 ICU : Done\n",
      "Fitting - Mt St Joseph DC2B00 EMERG HAU OP MSJ : Done\n",
      "Fitting - Mt St Joseph DC2B00 MSJ NURSING UNITS : Done\n",
      "Fitting - Mt St Joseph DC2B00 SPD : Done\n",
      "Fitting - Mt St Joseph DC1000 MSJ OR PAR DT CL : Done\n",
      "Fitting - Mt St Joseph DC1000 ICU : Done\n",
      "Fitting - Mt St Joseph DC1000 PARKVIEW, 1 SOUTH : Done\n",
      "Fitting - Mt St Joseph DC1000 EMERG HAU OP MSJ : Done\n",
      "Fitting - Mt St Joseph DC1000 MSJ NURSING UNITS : Done\n",
      "Fitting - Mt St Joseph DC1000 RES SVCS MSJ : Done\n",
      "Fitting - Mt St Joseph DC2A00 MSJ OR PAR DT CL : Done\n",
      "Fitting - Mt St Joseph DC2A00 PARKVIEW, 1 SOUTH : Done\n",
      "Fitting - Mt St Joseph DC2A00 EMERG HAU OP MSJ : Done\n",
      "Fitting - Mt St Joseph DC2A00 MSJ NURSING UNITS : Done\n",
      "Fitting - Mt St Joseph DC2A00 RES SVCS MSJ : Done\n",
      "Fitting - Mt St Joseph DC2A00 ACCESS SVCS MSJ : Done\n",
      "Fitting - Holy Family DC1000 REHAB HFH : Done\n",
      "Fitting - Holy Family DC1000 RES SVCS HFH : Done\n",
      "Fitting - Holy Family DC2A00 REHAB HFH : Done\n",
      "Fitting - Holy Family DC2A00 RES SVCS HFH : Done\n",
      "Fitting - Brock Fahrni DC1000 RES SVCS BF : Done\n",
      "Fitting - Brock Fahrni DC2A00 RES SVCS BF : Done\n",
      "Fitting - Youville Residence DC2B00 PARKVIEW, 1 SOUTH : Done\n",
      "Fitting - Youville Residence DC1000 PARKVIEW, 1 SOUTH : Done\n",
      "Fitting - Youville Residence DC1000 RES SVCS YOUV : Done\n",
      "Fitting - Youville Residence DC2A00 RES SVCS YOUV : Done\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "# create and store predictions and true results\n",
    "models = {}\n",
    "data_individual = {}\n",
    "pred_results = {}\n",
    "for i in sites:\n",
    "    for j in job_families:\n",
    "        for k in sub_programs:\n",
    "            temp_data = data_group[(data_group[\"SITE\"]==i) & (data_group[\"JOB_FAMILY\"]==j) & (data_group[\"SUB_PROGRAM\"]==k)].reset_index()\n",
    "            temp_data = pd.merge(timeframe_past, temp_data, on=\"ds\", how=\"outer\")\n",
    "            temp_data[\"y\"] = temp_data[\"y\"].fillna(0)\n",
    "\n",
    "            if temp_data[\"y\"].sum() >= 300.0:\n",
    "                data_individual[(i, j, k)] = temp_data\n",
    "                pred_results[(i, j, k)], models[(i, j, k)] = run_prophet(temp_data, timeframe_future)\n",
    "                print(\"Fitting -\", i, j, k, \": Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = {}\n",
    "for i in data_individual.keys():\n",
    "    # create week column\n",
    "    combined= pred_results[i][[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]]\n",
    "    combined[\"week\"] = combined[\"ds\"].dt.week\n",
    "    combined[\"ds\"] = combined[\"ds\"]-pd.DateOffset(weekday=0, weeks=1)\n",
    "\n",
    "    # store y, yhat, yhat_lower, yhat_upper\n",
    "    weekly_yhat = combined.groupby(\"ds\").yhat.sum().round(0).astype(int).reset_index()\n",
    "    weekly_yhat_lower = combined.groupby(\"ds\").yhat_lower.sum().round(0).astype(int).reset_index()\n",
    "    weekly_yhat_upper = combined.groupby(\"ds\").yhat_upper.sum().round(0).astype(int).reset_index()\n",
    "\n",
    "    # merge weekly results\n",
    "    weekly[i] = pd.concat([weekly_yhat[\"yhat\"],\n",
    "                           weekly_yhat_lower[\"yhat_lower\"],\n",
    "                           weekly_yhat_upper[\"yhat_upper\"]], axis=1)\n",
    "\n",
    "    # create columns \"year\", \"site\", \"JOB_FAMILY\"\n",
    "    length = weekly[i].shape[0]\n",
    "    weekly[i][\"ds\"] = combined[\"ds\"]\n",
    "    weekly[i][\"week\"] = combined[\"ds\"].dt.weekofyear\n",
    "    weekly[i][\"site\"] = np.repeat(i[0], length)\n",
    "    weekly[i][\"job_family\"] = np.repeat(i[1], length)\n",
    "    weekly[i][\"sub_program\"] = np.repeat(i[2], length)\n",
    "\n",
    "    # code for minimizing errors (model residuals)\n",
    "    forecasted = models[i].predict(timeframe_future)\n",
    "    actual = data_individual[i]\n",
    "\n",
    "    # get residuals\n",
    "    error = actual[\"y\"] - forecasted[\"yhat\"]\n",
    "    obs = timeframe_past.copy()\n",
    "    obs[\"error\"] = error\n",
    "    obs = obs.set_index(\"ds\")\n",
    "\n",
    "    # model residuals\n",
    "    period = int((np.max(timeframe_future) - np.min(timeframe_future)).dt.days)+1\n",
    "    decomp = decompose(obs, period=period)\n",
    "    weekly_fcast = forecast(decomp, steps=period, fc_func=drift, seasonal=True)\n",
    "    weekly_fcast[\"week\"] = weekly_fcast.index-pd.DateOffset(weekday=0, weeks=1)\n",
    "    weekly_fcast = weekly_fcast.groupby(\"week\").sum()\n",
    "\n",
    "    # replace weekly data\n",
    "    resid_fcast = weekly_fcast.reset_index()[\"drift+seasonal\"]\n",
    "    weekly_yhat = (weekly[i][\"yhat\"] + resid_fcast).round(0)\n",
    "    weekly_yhat_lower = (weekly[i][\"yhat_lower\"] + resid_fcast).round(0)\n",
    "    weekly_yhat_upper = (weekly[i][\"yhat_upper\"] + resid_fcast).round(0)\n",
    "\n",
    "    # replace negatives with 0s\n",
    "    weekly[i][\"yhat\"] = weekly_yhat.where(weekly_yhat >= 0, 0)\n",
    "    weekly[i][\"yhat_lower\"] = weekly_yhat_lower.where(weekly_yhat_lower >= 0, 0)\n",
    "    weekly[i][\"yhat_upper\"] = weekly_yhat_upper.where(weekly_yhat_upper >= 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data/predictions folder if it doesn't exist\n",
    "predictions_path = \"../data/predictions/\"\n",
    "if not os.path.exists(predictions_path):\n",
    "    os.mkdir(predictions_path)\n",
    "\n",
    "\n",
    "# export to \"data/predictions/\" directory\n",
    "total_data = pd.DataFrame()\n",
    "for i in weekly:\n",
    "    total_data = pd.concat([total_data, weekly[i]], axis=0)\n",
    "total_data.to_csv(predictions_path + \"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
