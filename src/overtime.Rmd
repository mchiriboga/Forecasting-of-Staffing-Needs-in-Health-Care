---
title: "Overtime Pattern"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# packages
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(prophet))
suppressPackageStartupMessages(library(MLmetrics))
```

## Introduction

In this draft we explore the overtime pattern for the nurses. We consider the data related to the following two values:

- `Overtime` in `EARNING_CATEGORY` column, indicating the excepted is backfilled by overtime, and
- `NURS` in `LABOR_AGREEMENT` column, indicating the position is nurse.

Since overtime backfill is expensive, we want to know the percentage of exception backfilled by "overtime" over the total number of exceptions, in order to take actions before hand. We use Facebook's Prophet model for predicting, and LOESS moving average for generating the intervals.

As a result, for each week of the dates to be predicted, we give a predicted percentage and an interval with more than 90% confidence.

## Load Data

For tuning the model, we use the training data, including the exceptions from end of 2012 to end of 2017.

```{r Load data}
df <- read_csv("../data/train.csv")
```

## Overall Weekly Pattern

Below is some EDA for the weekly pattern of overtime percentage. We can see there is some pattern in the graphs:

- Trend decrease from January, reach the bottom at around week 34.
- From Week 34, increase till the end of the year.

```{r Overall: Weekly Analysis}
# for each week, get the percentage of "Overtime" over all exceptions
# ds: first day of that week
overall <- df %>% 
  mutate(ds = floor_date(SHIFT_DATE, unit = "week"), # first day of the week
         overtime = EARNING_CATEGORY == "Overtime") %>% 
  group_by(ds) %>% 
  summarise(over = sum(overtime), total = n()) %>% 
  mutate(y = over/total) %>% 
  select(ds, y)

## visualization
overall %>% 
  ggplot() +
  geom_line(aes(x = week(ds), y = y, color = factor(year(ds))))
```

## Labor Agreement: Nurse

First we prepare data for the group of nurse: 

```{r Nurse: data}
nurse <- df %>% 
  filter(LABOR_AGREEMENT == "NURS")

# check the amount of data we have
nrow(nurse)
```

```{r Nurse: EDA}
# get the percentage of "Overtime" over all exceptions
nurse_daily <- nurse %>% 
  mutate(overtime = EARNING_CATEGORY == "Overtime") %>% 
  group_by(SHIFT_DATE) %>% 
  summarise(over = sum(overtime), total = n()) %>% 
  mutate(y = over/total) %>% 
  select(ds = SHIFT_DATE, y)

# get the average percentage of a week
# ds: first day of that week
nurse_weekly <- nurse_daily %>% 
  mutate(ds = floor_date(ds, unit = "week")) %>% 
  group_by(ds) %>% 
  summarise(y = mean(y))

## visualization
ggplot() +
  geom_line(data = nurse_weekly, aes(x = week(ds), y = y, color = factor(year(ds))))
```

Then we make the prediction by Prophet.

```{r Nurse: Predict by Prophet}
# split train and validate
train <- nurse_daily %>% 
  filter(year(ds) < 2017)

# get the end date of training set
end_date <- max(train$ds)

# generate model
m <- prophet(train, 
             yearly.seasonality = TRUE,
             interval.width = 0.62)
  
# predict
future <- make_future_dataframe(m, periods = 365)
prediction <- predict(m, future)
```

```{r Nurse: Prediction Results}
# aggregate the predicted result by week
pred_all <- prediction %>% 
  mutate(ds = floor_date(ds, unit = "week")) %>% 
  group_by(ds) %>% 
  summarise(yhat = mean(yhat))

# aggregate the validation data by week
val_all <- nurse_weekly %>% 
  mutate(val_split = year(ds) >= 2017)

# make a visualize of the predicted data we have
ggplot() +
  geom_line(data = val_all, aes(x = as.Date(ds), y = y, color = "Actual Data")) +
  geom_line(data = pred_all, aes(x = as.Date(ds), y = yhat, color = "Prediction"))
```

```{r}
# make a visualization for the prediction period: 2017
pred_17 <- pred_all %>% 
  filter(year(ds) > 2016)

val_17 <- val_all %>% 
  filter(year(ds) > 2016) %>% 
  select(ds, y)

ggplot() +
  geom_line(data = val_17, aes(x = as.Date(ds), y = y, color = "Val")) +
  geom_line(data = pred_17, aes(x = as.Date(ds), y = yhat, color = "Pred"))
```

We can see we have a pretty good prediction on the validation set.

Besides, other that just a number, we also want to provide an interval for the prediction. We use LOESS moving average to smooth the prediction we have, and make adjustments to generate an interval.

```{r Nurse: Intervals}
# Idea: Use Loess to get a smoothed interval
pp <- pred_all %>% 
  mutate(id = week(ds))

ll <- loess(yhat ~ week(ds), data = pp, span = 0.3)
out <- predict(ll)

interval <- pred_all %>% 
  mutate(upper = out + 0.03,
         lower = out - 0.014)

# visualize the intervals
ggplot() +
  geom_line(data = val_all, aes(x = as.Date(ds), y = y, color = "Val")) +
  geom_line(data = interval, aes(x = as.Date(ds), y = yhat, color = "yhat")) +
  geom_line(data = interval, aes(x = as.Date(ds), y = upper, color = "loess")) +
  geom_line(data = interval, aes(x = as.Date(ds), y = lower, color = "loess"))
```

```{r Nurse: Accuracy}
result <- interval %>% 
  mutate(y = val_all$y) %>% 
  filter(year(ds) > 2016) 

result %>% 
  mutate(test = y < upper & y > lower) %>% 
  group_by() %>% 
  summarise(sum = sum(test)) %>% 
  mutate(accuracy = sum/nrow(result))
```

The accuracy that the prediction falls in the interval on the validation set is around `96%`. However, the validation set is small, so the accuracy might not indicate that the accuracy will always be that high.

## Sample Output

For the give dates, we have an prediction and an interval for each week.

```{r}
head(result)
```

